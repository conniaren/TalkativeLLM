{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import pyaudio\n",
    "import subprocess\n",
    "import json\n",
    "#from vosk import Model, KaldiRecognizer\n",
    "from deepspeech import Model\n",
    "import time\n",
    "import numpy as np\n",
    "import whisper\n",
    "import torch\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECS = 20\n",
    "SAMPLE_SIZE = 2\n",
    "BEAM_WIDTH = 100\n",
    "ALPHA = 0.93\n",
    "BETA = 1.18\n",
    "FINAL_STR = []\n",
    "\n",
    "messages = Queue()\n",
    "recordings = Queue()\n",
    "\n",
    "record_button = widgets.Button(\n",
    "    description=\"Record\",\n",
    "    disabled = False,\n",
    "    button_style = \"success\",\n",
    "    icon = 'microphone'\n",
    ")\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description=\"Stop\",\n",
    "    disabled = False,\n",
    "    button_style = \"warning\",\n",
    "    icon = 'stop'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def record_mic(chunk = CHUNK):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels = CHANNELS, rate = RATE, input = True, frames_per_buffer=chunk)\n",
    "\n",
    "    frames = []\n",
    "    while not messages.empty():\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    " \n",
    "        if len(frames) >= RATE//CHUNK*RECORD_SECS:\n",
    "            recordings.put(frames.copy())\n",
    "            frames = []\n",
    "        \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "'''\n",
    "model = Model('/Users/connia/vosk-model-en-us-0.22')\n",
    "rec = KaldiRecognizer(model,RATE)\n",
    "rec.SetWords(True)\n",
    "'''\n",
    "\n",
    "'''\n",
    "model = Model('./models/deepspeech-0.9.3-models.pbmm')\n",
    "model.enableExternalScorer('./models/deepspeech-0.9.3-models.scorer')\n",
    "model.setBeamWidth(BEAM_WIDTH)\n",
    "model.setScorerAlphaBeta(ALPHA,BETA)\n",
    "stream_model = model.createStream()\n",
    "'''\n",
    "\n",
    "model = whisper.load_model('base.en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognition(output):\n",
    "    while not messages.empty():\n",
    "        frames = recordings.get()\n",
    "\n",
    "        #rec.AcceptWaveform(b''.join(frames))\n",
    "        #result = rec.Result()\n",
    "        data16 = np.frombuffer(b''.join(frames), dtype=np.int16)\n",
    "        data32 = data16.astype(np.float32)/32768.0\n",
    "        \n",
    "        #stream_model.feedAudioContent(data16)\n",
    "        #text = json.loads(result)['text']\n",
    "        result = model.transcribe(data32)\n",
    "        FINAL_STR.append(result[\"text\"]+'\\n')\n",
    "\n",
    "        #case = subprocess.check_output(\"python vosk-recasepunc-en-0.22/recasepunc.py predict vosk-recasepunc-en-0.22/checkpoint\", shell = True, text = True, input = text)\n",
    "        #print(stream_model.intermediateDecode())\n",
    "        output.append_stdout(result[\"text\"]+'\\n')\n",
    "        #time.sleep(1)\n",
    "    \n",
    "\n",
    "\n",
    "def start_recording(data):\n",
    "    messages.put(True)\n",
    "    with output:\n",
    "        display(\"Starting recording ...\")\n",
    "        record = Thread(target = record_mic)\n",
    "        record.start()\n",
    "\n",
    "        transcribe = Thread(target = speech_recognition, args= (output, ))\n",
    "        transcribe.start()\n",
    "\n",
    "def stop_recording(data):\n",
    "    with output:\n",
    "        messages.get()\n",
    "        display (\"Recording Finished. \")\n",
    "        #FINAL_STR = stream_model.finishStream()\n",
    "        display(''.join(FINAL_STR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6954fc77ccd540ecba4155d412edd222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337d6f67aa2d4a9f9b02f512511de689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef6024181164726a623b25b1b5a20b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connia/tmp/deepspeech-venv/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "record_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "display(record_button, stop_button, output)\n",
    "print(FINAL_STR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeech-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
